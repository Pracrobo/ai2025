response.data.choices[0].message
{
  role: 'assistant',
  content: 'I can help you find a recipe or suggest a nearby restaurant. What type of cuisine are you in the mood for?',
  refusal: null,
  annotations: []
}

랜덤 값으로 비슷하게 보낼수도 다를 수도 암튼 그럼
질문이 들어갈대마다 랜덤

### 주요 파라미터 (v1/chat/completions 기준)
파라미터	설명	예시 / 기본값
model	사용할 모델 이름	"gpt-4", "gpt-3.5-turbo" 등
messages	대화 형식의 입력 메시지 목록 (역할 + 내용)	[{"role": "user", "content": "안녕"}]
temperature	출력의 무작위성 제어 (0.0 ~ 2.0)	기본값: 1.0
top_p	nucleus sampling 제어 (0.0 ~ 1.0) - temperature와 같이 사용하지 않는 게 일반적	기본값: 1.0
n	몇 개의 응답을 생성할지 지정	기본값: 1
stream	스트리밍 응답 여부 (true 시 부분 응답 실시간 수신)	기본값: false
stop	응답 생성을 중단할 문자열 또는 문자열 배열	예: ["\n\n", "user:"]
max_tokens	응답에서 생성할 최대 토큰 수 제한	예: 1000
presence_penalty	새로운 주제를 유도하는 정도 (-2.0 ~ 2.0)	기본값: 0.0
frequency_penalty	반복 억제 정도 (-2.0 ~ 2.0)	기본값: 0.0
logit_bias	특정 토큰의 생성 확률 조정 (고급 사용)	예: { "50256": -100 }
user	사용자 식별자 (안전성/사용 추적 목적)	예: "user-1234"

### 자주 조정하는 핵심 파라미터 요약
temperature: 창의성 조절

top_p: 확률 누적 기반 제어 (temperature와 함께 사용하지 않는 게 일반적)

max_tokens: 응답 길이 제한

stop: 멈출 조건

stream: 실시간 출력이 필요할 때 사용

