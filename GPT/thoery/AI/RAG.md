# RAG : Retrieval-Augmented Generation(검색 증강 생성)

RAG는 검색 모듈이 찾은 외부 문서를 LLM의 프롬프트에 주입해 사실 기반 응답을 생성하도록 설계된 지식-집약적 언어처리 프레임 워크이다.

- 질문 응답 지식 기반 챗봇에서 파라미터만으로는 부족한 최신 지식을 보완하기 위한 방법으로 자리잡았고 2024년 이후 빅테크가 급격히 채택하면서 산업 표준으로 정착했다.

## 작동원리

1. 인덱싱 단계 : 도메인 데이터를 임베딩 벡터로 변환해 벡터 데이터베이스에 저장한다.
2. 검색 단계 : 사용자의 질의를 임베딩해서 K-최근접 탐색으로 관련 문서를 검색한다.
3. 증강 단계 : 검색 문서를 잘라(concatenate, chunk) LLM 프롬프트에 삽입한다.
4. 생성 단계 : LLM이 증강된 프롬프트를 받아 최종 답변을 생성하고 필요하면 출처를 인용한다.

- 토큰마다 다른 문서를 조건화하는 RAG-Token
- 시퀀스 전체에 동일 문서를 사용하는 RAG-Sequence

## 장점

- 지식의 최신성 확보: 모델 재훈련 없이 새 데이터를 즉시 활용한다.
- 할루시넹션 감소: 근거 문서를 명시해 답변의 사실성을 높인다.
- 비용 절감: 파라미터 업데이트가 필요없으므로 계산, 운영비가 낮다.
- 투명성: 응답과 함께 문서 링크를 제시해 검증 가능성이 커진다.


## 한계, 과제
- 검색기 성능에 따라 답변 품질이 좌우된다.
- 장문 문서가 프롬프트 길이를 초과하면 정보 손실이 발생한다.
- 신뢰도 낮은 문서를 가져오면 근거 기반 거짓말이 될 위험이 있다.
- 평가 기준 부재: 검색과 생성 두 단계를 함께 측정할 통합 지표가 연구중...


## 활용사례
- 사내 정책/지식관리 챗봇
- 의료/법률 도메인 전문 QA
- 코드 보조, 논문 요약, 검색 기반 글쓰기
- 멀티 모달 확장(이미지+텍스트 RAG) 및 에이전트 시스템의 "장기메모리" 구성